---
title: 02.Bayesian networks
index: true
icon: "/assets/icon/common/data-mining.svg"
icon-size: "4rem"
author: Haiyue
date: 2023-08-17
category:
  - Guide
---

## Bayesian networks: examples, definition
::: details
::: tabs
@tab Bayesian network 1
![Bayesian Network 1](/data/unisa/AdvancedAnalytic2/week3/BayesianNetwork1.png)
@tab Bayesian network 2
![Bayesian Network 2](/data/unisa/AdvancedAnalytic2/week3/BayesianNetwork2.png)
:::

## Bayesian networks
### What is a BN?
**A Bayesian network (BN) is a <span style="color:red;font-weight:bold"> graphical model</span> for depicting probabilistic relationships among a set of variables.**
* BN Encodes the <span style="color:orange;font-weight:bold">conditional independence relationships</span> between the variables in the graph structure. 
* Provides a <span style="color:orange;font-weight:bold">compact representation of the joint probability distribution</span> over the variables 
* A problem domain is modeled by a list of variables $X_1, …, X_n$ 
* Knowledge about the problem domain is represented by a joint probability $P(X_1, …, X_n)$
* <span style="color:orange;font-weight:bold">Directed links represent causal direct influences</span>
* Each node has a <span style="color:orange;font-weight:bold">conditional probability table</span> quantifying the effects from the parents. 
* <span style="color:red;font-weight:bold">No directed cycles</span>
::: info Two important properties of Bayesian Networks
01. <span style="color:red;font-weight:bold">Encodes the conditional independence relationships</span> between the variables in the graph structure
02. Is a <span style="color:red;font-weight:bold">compact representation</span> of the joint probability distribution over the variables

:::

### Components of A Bayesian Network
A Bayesian Network is consisted with two components
1. **A directecd Acyclic Graph**
    ```mermaid
    ---
    title: A directecd Acyclic Graph
    ---
    flowchart TB
        A-->B-->C & D
    ```
    ::: info Characteristics
    01. Each node in the graph is a random variable
    02. A node X is a parent of another node Y if there is an arrow from node X to node Y 
        **eg.** A is a parent of B 
    03. Informally, an arrow from node X to node Y means X has a <span style="color:orange;font-weight:bold;">direct influence</span> on Y
    :::
2. A set of **tables for each node** in the graph
![Alt text](/data/unisa/AdvancedAnalytic2/week3/TablesForBayesianNetwork.png)
    ::: info Characteristics
    01. Each node $X_i$ has a <span style="color:orange;font-weight:bold;">conditional probability distribution</span> $P(X_i | Parents(X_i))$ that quantifies the effect of the parents on the node
    02. The parameters are the probabilities in these conditional probability tables (CPTs)
    :::
#### Using a Bayesian Network Example
Using the network in the example, suppose you want to calculate:
$$
\begin{equation}
\begin{split}   
P(A = & true, B = true, C = true, D = true) \\
&= P(A = true) * P(B = true | A = true) * \\
& * P(C = true | B = true) P( D = true | B = true) \\
  & = (0.4)*(0.3)*(0.1)*(0.95)
\end{split}
\end{equation}     
$$
Details for data refer to [here.](#components-of-a-bayesian-network)

### Conditional Independence
#### [The Markov condition](https://en.wikipedia.org/wiki/Causal_Markov_condition)
![The Markov condition](/data/unisa/AdvancedAnalytic2/week3/Markov.png)
Given its parents (P1, P2), a node (X) is <span style="color:orange;font-weight:bold;">conditionally independent</span> of its <span style="color:green;font-weight:bold;">non-descendants</span> (ND1, ND2). 
#### Conditional independence
![](/data/unisa/AdvancedAnalytic2/week3/BayesianNetwork1.png)


### The Joint Probability Distribution
Due to the Markov condition, we can compute the joint probability distribution over all the variables $X_1, …, X_n$ in the Bayesian net using the formula:
::: center
$P(X_1 = x_1, ..., X_n=x_n) = \prod_{i=1}^{n}P(X_i=x_i|Parents(X_i))$
:::
::: info
Where $Parents(X_i)$ means the values of the Parents of the node $X_i$ with respect to the graph 
:::


## Bayesian network inference
* <span style="color:orange;font-weight:bold;">Using a Bayesian network</span> to <span style="color:orange;font-weight:bold;">compute probabilities</span> is called inference
* In general, inference involves queries of the form:	<span style="color:orange;font-weight:bold;">$P( X | E )$</span>
    > ***E***: The evidence variable(s)
    > ***X***: The query variable(s)

* Diagnostic (evidential, abductive): from effect to cause
    - P(Buglary|JonhCalls), P(B|J)=0.016
    - P(B|J,M)=0.29
    - P(A|J,M)=0.76
* Causal (predictive): From cause to effect
    - P(J|B)=0.86
    - P(M|B)=0.67
* Intercausal (explaining away): common effect
    - P(B|A)=0.38
    - P(B|A, E)=0.003
* Mixed: two or more of the above combined
    - P(A|J,E’)=0.03
    - P(B|J,E’)=0.017

## Summary
## References
01. **Naive Bayes Classifier**
    ::: details Resource from Youtube
    <YouTube id="0MCMsdPKLyQ" />
    :::
02. **Week 3 Slides from [Thuc](https://people.unisa.edu.au/thuc.le) (SP52023)**