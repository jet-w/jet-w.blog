---
title: 01. Time Series Analysis
index: true
icon: timeline
author: Haiyue
date: 2023-08-09
category:
  - math
tag:
  - Time Series
---

## Basic Definition but Important
### What is time series
A series data indexed by date.

### What is power spectrum
The power spectrum (a.k.a., autospectrum or autospectral density) is the <span style="color:orange; font-weight: bold">distribution</span> of the total variance of a time series over <span style="color:orange; font-weight: bold">frequency</span>.
<span style="color:orange; font-weight: bold">Another words, power spectrum is a method, which could broken down into weighted sum of sin waves for a time series data. </span>

::: details Video for power spectrum
<YouTube id="Gka11q5VfFI" />
A time series data could be broken down into weighted sum of sin waves. Each wave has three important features, frequency, amplitude and phase. The most important frequencies have similar weights as we add in the other frequencies we get the entire power spectrum, note the <span style="color:orange; font-weight: bold">phase information has been <span style="color:red; font-weight: bold">discarded</span></span>. We can smooth it out a bit and now by taking the logarithm, we get the log power spectrum, which tells us the relative importance of each frequency component to the overall .
:::

### What is Fourier Transform
<span style="color:orange; font-weight: bold">All periodical data</span> could be broken down into <span style="color:orange; font-weight: bold">sum of several weighted sin waves</span>. 
::: details Video for Fourier Transform
<YouTube id="spUNpyF58BY" />
:::
::: info References
01. [How to understand Fourier Transform](https://www.youtube.com/watch?v=0LuyxzqI3Hk&t=898s)
:::
### What is seasonality
Seasonality is the presence of <span style="color:orange; font-weight: bold">variations</span> that occur at <span style="color:orange; font-weight: bold">specific regular intervals</span>(hourly, daily, weekly, monthly, yearly, etc.).

::: details Video for Seasonality
<YouTube id="4hrMdu9CSQs" />
:::

### What is Auto Correlation (ACF)
A time series is a sequence of measurements of the same variable(s) made over time. The coefficient of correlation between two values in a time series is called the autocorrelation function (ACF). 

::: info Other words
> Autocorrelation represents <span style="color:orange">the degree of similarity</span> between a given time series and a lagged version of itself over successive time intervals.

> Autocorrelation measures <span style="color:orange">the relationship between a variable’s current value and its past values</span>.

> An autocorrelation of +1 represents a perfect positive correlation, while an autocorrelation of negative 1 represents a perfect negative correlation.
:::

::: tip The importantance
01. Help us <span style="color:orange">uncover hidden patterns</span> in our data and help us <span style="color:orange">select the correct forecasting methods</span>.
02. Help <span style="color:orange">identify seasonality</span> in our time series data.
03. Analyzing the autocorrelation function (ACF) and partial autocorrelation function (PACF) in conjunction is necessary for <span style="color:orange">selecting the appropriate ARIMA model</span> for any time series prediction.
04. The autocorrelation analysis helps <span style="color:orange">detect patterns and check for randomness</span>. 
05. It’s <span style="color:red">especially important</span> when you intend to use an <span style="color:red">autoregressive–moving-average (ARMA) model</span> for forecasting because it helps to <span style="color:red">determine its parameters</span>. 
:::

::: info References
01. [Interpreting ACF or Auto-correlation plot](https://medium.com/analytics-vidhya/interpreting-acf-or-auto-correlation-plot-d12e9051cd14)
02. [Interpreting ACF and PACF Plots for Time Series Forecasting](https://towardsdatascience.com/interpreting-acf-and-pacf-plots-for-time-series-forecasting-af0d6db4061c)
:::
### What is AR, MA, ARMA, ARIMA
::: tabs
@tab AR
#### Background information
> 
@tab MA
#### Background information
> 
@tab ARMA
#### Background information
> In time series, we often <span style="color:orange">rely on past data</span> to make <span style="color:orange">estimates about current and future values</span>. However, sometimes that’s not enough. When unexpected events like natural disasters, financial crises, or even wars happen, there can be a sudden shift in values. That's why we need models that simultaneously use past data as a foundation for estimates, but can also quickly adjust to unpredictable shocks.



Autoregressive Moving Average (ARMA) is a model, which <span style="color:orange">takes into account past values</span>, as well as past errors <span style="color:orange">when constructing future estimates</span>. It comes from merging two simpler models - [the Autoregressive, or AR](https://365datascience.com/tutorials/time-series-analysis-tutorials/autoregressive-model/), and the [Moving Average, or MA](https://365datascience.com/tutorials/time-series-analysis-tutorials/moving-average-model/).

#### What is ARMA model looks like

Let’s suppose that “Y” is some random time-series variable. A simple Autoregressive Moving Average model would be like:

$y_t = c + \phi_1y_{(t-1)} + \theta_1\in_{(t-1)} + \in_{t}$

$y_t$: Values in the current period.
$y_{(t-1)}$: Values of 1 period ago respectively.
$\in_{t}$: Error terms for the current period.
$\in_{(t-1)}$: Error terms of 1 period ago respectively.
$c$: A baseline constant factor.
$\phi_1$: Expresses average what part of the value last period $y_{(t-1)}$ is relevant in explaining the current one. 
$\theta_1$: Expresses average what part of the error last period $\in_{(t-1)}$ is relevant in explaining the current one. 
::: tip
The error term from the last period is used to help us correct our predictions.

:::

::: info References
01. [What Is an ARMA Model?](https://365datascience.com/tutorials/time-series-analysis-tutorials/arma-model/)
02. [What Is an Autoregressive Model?](https://365datascience.com/tutorials/time-series-analysis-tutorials/autoregressive-model/)
03. [What Is a Moving Average Model?](https://365datascience.com/tutorials/time-series-analysis-tutorials/moving-average-model/)
:::


## Methods
### How to remove seasonality
There are two forms of ridding the original of seasonality, by either <span style="color:orange; font-weight: bold">dividing</span> by **appropriate seasonal indices** or by <span style="color:orange; font-weight: bold">subtracting</span> them.

#### Method
* Form the mean for each season
* $\bar{x_i}=\frac{1}{4}\sum_{j=1}^{4}x_i + 4j$
* $\hat{x_i} = x_i - \bar{x_i}$ for additive.
* $\hat{x_i} = \frac{x_i}{\bar{x_i}}$ for multiplicative.


###  Fourier Series Model for Seasonality
Using Fourier Series Model for modeling Seasonality.

Any periodic function satisfies the relation:$f(t) = f (t + T)$ where $T$ is the period of the function.
The simplest and <span style="color:red; font-weight: bold">most common periodic functions</span> are the <span style="color:red; font-weight: bold">trigonometric functions</span>. The functions $sin(nt)$ and $cos(nt), n ∈ 0, 1, 2, 3...$ being [harmonic](https://www.techtarget.com/whatis/definition/harmonic#:~:text=A%20harmonic%20is%20a%20wave,the%20reference%20signal%20or%20wave.) are by definition periodic with periods $\frac{2π}{n}$. Because trigonometric functions are <span style="color:orange; font-weight: bold">relatively <span style="color:red">easy</span> to work with</span> and because they possess <span style="color:orange; font-weight: bold">the important property of <span style="color:red">orthogonality</span></span> they are useful to represent the seasonality of data of this type.

#### orthonormal set.
::: center
<span style="color:red;font-weight:bold">$\frac{1}{\sqrt{2\pi}},\frac{sin(t)}{\sqrt{\pi}},\frac{cos(t)}{\sqrt{\pi}},\frac{sin(2t)}{\sqrt{\pi}},\frac{cos(2t)}{\sqrt{\pi}},\frac{sin(3t)}{\sqrt{\pi}},\frac{cos(3t)}{\sqrt{\pi}} ...$</span>
:::
Because this set of functions is complete in the interval $0 ≤ t ≤ 2π$ every function $f(t)$ which is continuous in that interval can be represented by the ***Fourier Series***
::: center
<span style="color:red;font-weight:bold">$f (t) = \frac{1}{2}a_0 + \displaystyle\sum_{r=1}^{\infin}(a_r cos(rt) + b_r sin(rt))$
</span>
:::
where the constants <span style="color:orange;font-weight:bold">$a_r$</span> and <span style="color:orange;font-weight:bold">$b_r$</span> are known as the <span style="color:orange;font-weight:bold">Fourier coefficients</span>.

Now, if we multiply both sides by $cos(st)$ and integrate we get
$$
\begin{equation}
\begin{split}
   \int_{0}^{2\pi}f(t)cos(st\cdot dt) &= \frac{1}{2}a_0\int_{0}^{2\pi}cos(st) + \displaystyle\sum_{r=1}^{\infin}a_r\int_{0}^{2\pi}cos(rt)cos(st\cdot dt) \\
   &=\displaystyle\sum_{r=1}^{\infin}b_r\int_{0}^{2\pi}sin(rt)cos(st\cdot dt)
\end{split}
\end{equation}
$$

For $s = 0$, this yields $a_o = \frac{1}{π}\int_{0}^{2\pi}f(t)dt$ so $a_0$ may be referred to as the average value of $f(t)$. if $s\neq 0$ then it reduces to $a_r = \frac{1}{\pi}\int_{0}^{2\pi}f(t)cos(rd\cdot dt)$ and $b_r = \frac{1}{\pi}\int_{0}^{2\pi}f(t)sin(rt\cdot dt)$. When $f(t)$ is an even series, that is, $f(t)$ is reflected at the origin, the $b$ coefficients vanish and the series is known as a Fourier cosine series. Similarly when the series is an odd series, $f(t) = −f(−t)$ the a coefficients vanish and the series is known as a Fourier sine series.



### Discrete Fourier Transform <span style="color:orange;font-weight:bold">(DFT)</span>
* What we need for our purposes is the discrete version of the series representation.
* We also need to <span style="color:orange;font-weight:bold">adjust the period</span>, where in the case of the deaths data, the <span style="color:orange;font-weight:bold">fundamental period is 12 months</span>.
* We will also consider <span style="color:orange;font-weight:bold">how to find</span> how many terms we use in the expansion.

The discrete Fourier Transform of a sequence of $N$ real or complex numbers, $x_0, x_1, . . . , x_{_{N−1}}$ is the sequence of complex numbers $c_0, c_1, . . . , c_{_{N−1}}$ defined by
::: center
<span style="color:red;font-weight:bold"> $c_j = \frac{1}{N}\displaystyle\sum_{n=0}^{N-1}x_ne^{-\frac{2\pi jn}{N}}, j=0,1,...,N-1$ </span>
:::

### Inverse Discrete Fourier Transform <span style="color:orange;font-weight:bold">(IDFT)</span>
The original $x_j$ can be recovered using the <span style="color:orange;font-weight:bold">Inverse DFT or IDFT</span>, defined by
::: center
<span style="color:red;font-weight:bold"> $x_j = \frac{1}{N}\displaystyle\sum_{n=0}^{N-1}c_ne^{\frac{2\pi jn}{N}}, j=0,1,...,N-1$ </span>
:::
Assume $x_0, x_1, ..., x_{_{N-1}}$ are real numbers and thus $c_{_{N-j}} = c_j^*$
<span style="color:red;font-weight:bold">$x_j = a_0 + \displaystyle\sum_{n=1}^{\frac{N}{2}-1} (a_ncos(\frac{2\pi jn}{N}) + b_n sin(\frac{2\pi jn}{N})) + a_{_{N/2}}(-1)^j$</span> for $N$ <span style="color:red;font-weight:bold">even</span>

<span style="color:red;font-weight:bold">$x_j = a_0 + \displaystyle\sum_{n=1}^{\frac{N-1}{2}} (a_ncos(\frac{2\pi jn}{N}) + b_n sin(\frac{2\pi jn}{N}))$</span> for $N$ <span style="color:red;font-weight:bold">odd</span>



### Power Spectrum
* Note that is we used the <span style="color:red;font-weight:bold">formulae above</span> we would <span style="color:red;font-weight:bold">capture all the values</span>.
* But, the <span style="color:red;font-weight:bold">Principle of Parsimony</span> leads us to construct the model that fits the data best with the least number of coefficients.
* Note that this will also the one that is <span style="color:red;font-weight:bold">most identifiable</span> in a physical sense - it has meaning.
* We do this by <span style="color:red;font-weight:bold">identifying the most important frequencies</span> to include via using the so-called Power Spectrum.

I will use a particular form that has useful corresponding meaning:<span style="color:red;font-weight:bold">$I_j=\frac{a_j^2 + b_j^2}{2}$</span>
In this form, it also gives the variance explained by the inclusion of that frequency in the Fourier series.

### Fourier Series Representation
$$\begin{equation}
\begin{split}
dt &= a_0\\
   &+ a_1 cos(2πt/12) + b_1 sin(2πt/12)\\
   &+ a_2 cos(4πt/12) + b_2 sin(4πt/12)\\
   &+ a_3 cos(6πt/12) + b_3 sin(6πt/12)
\end{split}
\end{equation}$$

### Methods of Estimating Parameters
* Direct calculation.
* Optimisation.
* Linear Regression.
* I will show how to do all of these, but in the next slides I will show a particular form of how to use regression for this.


### Normal Equations for Regression
$$\begin{equation}
\begin{split}
\hat
{D}(t) &= a_0 \\
   &+ a_1 cos(2\pi t/12) + a_2 sin(2\pi t/12) \\
   &+ a_3 cos(4πt/12) + a_4 sin(4πt/12)\\
   &+ a_5 cos(6πt/12) + a_6 sin(6πt/12)
\end{split}
\end{equation}$$
Let 
::: center
$x_1 = cos(2πt/12)$, 
$x_2 = sin(2πt/12)$, 
$x_3 = cos(4πt/12)$, 
$x_4 = sin(4πt/12)$, 
$x_5 = cos(6πt/12)$, 
$x_6 = sin(6πt/12)$. 
:::
Therefore we can rewrite the formula above as
::: center
$$\begin{equation}
\begin{split}
\hat{D}(t) = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + a_4x_4 + a_5x_5 + a_6x_6
\end{split}
\end{equation}$$
:::

### Derivation
The problem is to find $a_0, a_1, ... a_6$ to minimise the sum of squared deviations between the model and the data over the day.
::: center
$$\begin{equation}
\begin{split}
E &= \displaystyle\sum_{t=t_0}^{t_n}(\hat{S}(t)-S(t))^2\\
  &= \displaystyle\sum_{t=t_0}^{t_n}(a_0 + \displaystyle\sum_{j=1}^{6}a_jx_j(t) - S(t))^2
\end{split}
\end{equation}$$
:::
To calculate $a_0, a+1, ... a_6$, we take the partial derivatives of $E$ with respect to each and set these to zero to form a system of linear equations which we then solve.
::: center
$$\begin{equation}
\begin{split}
\frac{\partial E}{\partial a_0} &= 2\displaystyle\sum_{t=t_0}^{t_n}(a_0 + \displaystyle\sum_{j=0}^{6}a_jx_j(t)-S(t)) = 0\\
\frac{\partial E}{\partial a_1} &= 2\displaystyle\sum_{t=t_0}^{t_n}x_1(a_0 + \displaystyle\sum_{j=0}^{6}a_jx_j(t)-S(t)) = 0\\
....... &= ...........\\
\frac{\partial E}{\partial a_6} &= 2\displaystyle\sum_{t=t_0}^{t_n}x_4(a_0 + \displaystyle\sum_{j=0}^{6}a_jx_j(t)-S(t)) = 0
\end{split}
\end{equation}$$
:::
The set of equations above can be written in the following form
$A\phi = B$
::: left
$$
A(7,7)=\begin{bmatrix}
   n & \sum_{t=t_0}^{t_n}x_1(t) & \dots & \sum_{t=t_0}^{t_n}x_6(t) \\
    \sum_{t=t_0}^{t_n}x_1(t) & \sum_{t=t_0}^{t_n}x_1^2(t) & \dots & \sum_{t=t_0}^{t_n}x_1(t)x_6t\\
   \vdots & \ddots & \ddots & \vdots \\
   \sum_{t=t_0}^{t_n}x_6(t) & \sum_{t=t_0}^{t_n}x_1(t)x_6(t) & \dots & \sum_{t=t_0}^{t_n}x_6^2(t)
\end{bmatrix}
$$
:::
::: left
$$
\phi=\begin{bmatrix}
   a_0 \\
   a_1 \\
   \vdots\\
   a_6
\end{bmatrix}
$$
$$
B=\begin{bmatrix}
   \sum_{t=t_0}^{t_n}S(t) \\
   \sum_{t=t_0}^{t_n}x_1(t)S(t) \\
   \vdots\\
   \sum_{t=t_0}^{t_n}x_6(t)S(t)
\end{bmatrix}
$$
$\phi = A^{-1}B$
:::


## Intraday Solar Radiation
* One can deal with the seasonalities inherent in climate variable in a multiplicative or additive modelling framework.
* Interestingly, though I will argue that the multiplicative approach is problematic, it is the approach most often used for solar forecasting models in particular. There are two versions of the multiplicative approach with respect to solar radiation, <span style="color:orange; font-weight: bold">calculating the clearness index</span>, and <span style="color:orange; font-weight: bold">estimating the clear sky index</span>.
* To form the clearness index, one divides the global solar radiation by the extraterrestrial radiation, a quantity determined only via astronomical formulae. On the other hand the clear sky index involves dividing the global radiation by a clear sky model.
* Note that the wind resource is not as seasonally dependent as the solar radiation, and both multiplicative and additive versions of dealing with seasonality are used.
* Additive de-seasoning is enacted through subtracting a mean function from the solar radiation, that function formed usually through the addition of terms involving a basis of the function space.
* I will argue that an appropriate way to perform this operation is through the use of a Fourier set of basis functions.

## Seasonality modelling methods
* Multiplicative, dividing the data by clearness index.
* Multiplicative, dividing the data by clearness sky model.
* Additive, using <span style="color:orange; font-weight: bold">Fourier series</span> or <span style="color:orange; font-weight: bold">wavelets</span>.

### Clearness Index - advantages and disadvantages
* It is a calculated, not modelled value as the divisor is the so-called extraterrestrial radiation $H_t$.
* $H_t$ is the result of a calculation using spherical trigonometry applied to the ‘solar constant’.
* From my experience it does not pick up all the seasonal effects.

### Clear Sky Index - advantages and disadvantages
* It is based on a physical model of a so-called clear sky, and varies throughout the year.
* It uses some parameter values that vary at high frequency but are assumed to vary at low frequency.
* There are several clear sky models - Ineichen evaluates thirteen.


## Seasonality
The first step is to identify and model the seasonality. We have identified several significant cycles using spectral analysis. Fourier series will be used in this step.
。。。。。。。

## Objectives of time series analysis
- Use model to provide compact description of data
- <span style="color:orange; font-weight: bold">Recognise</span> presence of seasonal components and <span style="color:orange; font-weight: bold">remove them</span> so <span style="color:orange; font-weight: bold">as not to confuse them with long-term trends</span> (**seasonal adjustment**).
- Other applications of time series models
    * Separation (or filtering) of noise from signals
    * Prediction of future values of a series
    * Testing hypotheses
    * Predicting one series from observations of another
    * Controlling future values of a series by adjusting parameters
- Time series models are also useful in simulation studies

## Some simple time series models
- Important part of time series analysis: select, suitable probability model for data
::: info Definition
A <span style="color:orange; font-weight: bold">time series model</span> for observed data ${x_t}$ is a specification of <span style="color:orange; font-weight: bold">the joint distributions</span> (or only means and covariances) of <span style="color:orange; font-weight: bold">a sequence of random variables</span> ${X_t}$ of which ${x_t}$ is a realization.
:::

- A complete probabilistic time series model for ${X_1, X_2, ...}$ specifies all the probabilities
::: center
$P[X_1 \leq x_1\text{, ..., }X_n \leq x_n ], -\infin \lt x_1, ..., x_n \lt \infin, n=1,2,...$
:::
Such a specification of all joint distributions is rarely used because it contains too many parameters to be estimated from avaliable data.

## References
01. https://www.youtube.com/watch?v=RwJnPw1tzKM
02. https://www.youtube.com/watch?v=aP05EpN1M58&list=PLYEmLA_7ilZPHis6d-xEGqQ_8Enuv_s32&index=4
03. https://www.youtube.com/watch?v=fav8_LGY75Y&list=PLYEmLA_7ilZPHis6d-xEGqQ_8Enuv_s32&index=2
04. https://www.youtube.com/watch?v=ikkOBWQj9X8&list=PLnG1U6UeKOIir0ytWi8GihemUFUZynWBL
05. https://www.youtube.com/watch?v=2mM8BUqWAZ4
06. [Reference 1](https://www.youtube.com/watch?v=Gka11q5VfFI)
07. [Reference 2](https://www.youtube.com/watch?v=spUNpyF58BY)
08. [Fourier transform](https://charlesliuyx.github.io/2018/02/18/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E8%AE%A9%E4%BD%A0%E6%B0%B8%E8%BF%9C%E5%BF%98%E4%B8%8D%E4%BA%86%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A7%A3%E6%9E%90/)
09. [Power Spectrum](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/power-spectrum)
10. The seasonality slides from [John](https://people.unisa.edu.au/john.boland) in SP52023.