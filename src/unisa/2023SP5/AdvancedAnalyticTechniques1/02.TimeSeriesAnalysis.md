---
title: 02.Time Series Analysis
index: true
icon: "/assets/icon/common/slides.svg"
author: Haiyue
date: 2023-08-09
category:
  - math
tag:
  - Time Series
---

## Key Points
01. Tread
02. Seasonality
03. ARMA
04. ARCH&GARCH
05. Rain model
06. Diffuse SolarRadiation
07. Synthetic Generation


## Basic Definition but Important

### What is time series
A series data indexed by date.

### What is power spectrum
The power spectrum (a.k.a., autospectrum or autospectral density) is the <span style="color:orange; font-weight: bold">distribution</span> of the total variance of a time series over <span style="color:orange; font-weight: bold">frequency</span>.
<span style="color:orange; font-weight: bold">Another words, power spectrum is a method, which could broken down into weighted sum of sin waves for a time series data. </span>

::: details Video for power spectrum
<YouTube id="Gka11q5VfFI" />
A time series data could be broken down into weighted sum of sin waves. Each wave has three important features, frequency, amplitude and phase. The most important frequencies have similar weights as we add in the other frequencies we get the entire power spectrum, note the <span style="color:orange; font-weight: bold">phase information has been <span style="color:red; font-weight: bold">discarded</span></span>. We can smooth it out a bit and now by taking the logarithm, we get the log power spectrum, which tells us the relative importance of each frequency component to the overall .
:::

### What is Fourier Transform
<span style="color:orange; font-weight: bold">All periodical data</span> could be broken down into <span style="color:orange; font-weight: bold">sum of several weighted sin waves</span>. 
::: details Video for Fourier Transform
<YouTube id="spUNpyF58BY" />
:::
::: info References
01. [How to understand Fourier Transform](https://www.youtube.com/watch?v=0LuyxzqI3Hk&t=898s)
02. [What is the Descrete Fourier Transform (DFT)](https://pythonnumericalmethods.berkeley.edu/notebooks/chapter24.02-Discrete-Fourier-Transform.html)
:::
### What is seasonality
Seasonality is the presence of <span style="color:orange; font-weight: bold">variations</span> that occur at <span style="color:orange; font-weight: bold">specific regular intervals</span>(hourly, daily, weekly, monthly, yearly, etc.).

::: details Video for Seasonality
<YouTube id="4hrMdu9CSQs" />
:::

### What is Auto Correlation (ACF)
A time series is a sequence of measurements of the same variable(s) made over time. The coefficient of correlation between two values in a time series is called the autocorrelation function (ACF). 

::: info Other words
> Autocorrelation represents <span style="color:orange">the degree of similarity</span> between a given time series and a lagged version of itself over successive time intervals.

> Autocorrelation measures <span style="color:orange">the relationship between a variable’s current value and its past values</span>.

> An autocorrelation of +1 represents a perfect positive correlation, while an autocorrelation of negative 1 represents a perfect negative correlation.
:::

::: tip The importantance
01. Help us <span style="color:orange">uncover hidden patterns</span> in our data and help us <span style="color:orange">select the correct forecasting methods</span>.
02. Help <span style="color:orange">identify seasonality</span> in our time series data.
03. Analyzing the autocorrelation function (ACF) and partial autocorrelation function (PACF) in conjunction is necessary for <span style="color:orange">selecting the appropriate ARIMA model</span> for any time series prediction.
04. The autocorrelation analysis helps <span style="color:orange">detect patterns and check for randomness</span>. 
05. It’s <span style="color:red">especially important</span> when you intend to use an <span style="color:red">autoregressive–moving-average (ARMA) model</span> for forecasting because it helps to <span style="color:red">determine its parameters</span>. 
:::

::: info References
01. [Interpreting ACF or Auto-correlation plot](https://medium.com/analytics-vidhya/interpreting-acf-or-auto-correlation-plot-d12e9051cd14)
02. [Interpreting ACF and PACF Plots for Time Series Forecasting](https://towardsdatascience.com/interpreting-acf-and-pacf-plots-for-time-series-forecasting-af0d6db4061c)
:::
### What is AR, MA, ARMA, ARIMA, GARCH
::: tabs
@tab AR
#### Background information
> In time-series, we often observe similarities between past and present values. That’s because we encounter autocorrelation within such data. In other words, by knowing the price of a product today, we can often make a rough prediction about its valuation tomorrow. So, in this tutorial, we’re going to discuss a model that reflects this correlation. – the autoregressive model.

The Autoregressive Model, or AR model for short, <span style="color:orange">relies only on past period values to predict current ones</span>. <span style="color:red">It’s a linear model</span>, where current period values are a sum of past outcomes multiplied by a numeric factor.

#### What it looks like
$x_t = C + \phi_1X_{t-1} + \in_t$

$X_{t-1}$: represents the value of X during the previous period.
$ϕ_1$: is the coefficient, which is a numeric constant by which we multiply the lagged variable $X_{(t-1)}$.
$\in_t$: It’s called the residual and represents the <span style="color:orange">difference between our prediction for period t and the correct value ($\in_t = y_t - \hat{y}_t$)</span>. These residuals are usually unpredictable differences because if there’s a pattern, it will be captured in the other incumbents of the model.

#### Autoregressive Model with More Lags
From a mathematical point of view, a model using two lags (AR(2)) would look as follows:

$X_t = C + ϕ_1 X_{t-1} + ϕ_2 X_{t-2} + ϵ_t$

@tab MA
#### Background information
> In time-series, we sometimes <span style="color:orange">observe similarities between past errors and present values</span>. That’s because <span style="color:red;font-weight:bold;">certain unpredictable events happen</span>, and they need to be accounted for.
> In other words, by <span style="color:orange">knowing how far off our estimation yesterday was</span>, compared to the actual value, we can tweak our model, so that it responds accordingly.

#### What it looks like
Let’s suppose that “r” is some time-series variable, like returns. Then, a simple Moving Average (MA) model looks like this:
$r_t = c+\theta_1\in_{t-1} + \in_t$

$r_t$: represents the values of “r” in the current period - t. 
$c$: stands for a constant factor.
$\theta_1$: numeric coefficient for the value associated with the 1st lag.
$ϵ_t$ and $ϵ_{t-1}$: represent the residuals for the current and the previous period, respectively.

@tab ARMA
#### Background information
> In time series, we often <span style="color:orange">rely on past data</span> to make <span style="color:orange">estimates about current and future values</span>. However, sometimes that’s not enough. When unexpected events like natural disasters, financial crises, or even wars happen, there can be a sudden shift in values. That's why we need models that simultaneously use past data as a foundation for estimates, but can also quickly adjust to unpredictable shocks.


Autoregressive Moving Average (ARMA) is a model, which <span style="color:orange">takes into account past values</span>, as well as past errors <span style="color:orange">when constructing future estimates</span>. It comes from merging two simpler models - [the Autoregressive, or AR](https://365datascience.com/tutorials/time-series-analysis-tutorials/autoregressive-model/), and the [Moving Average, or MA](https://365datascience.com/tutorials/time-series-analysis-tutorials/moving-average-model/).

#### What is ARMA model looks like

Let’s suppose that “Y” is some random time-series variable. A simple Autoregressive Moving Average model would be like:

$y_t = c + \phi_1y_{(t-1)} + \theta_1\in_{(t-1)} + \in_{t}$

$y_t$: Values in the current period.
$y_{(t-1)}$: Values of 1 period ago respectively.
$\in_{t}$: Error terms for the current period.
$\in_{(t-1)}$: Error terms of 1 period ago respectively.
$c$: A baseline constant factor.
$\phi_1$: Expresses average what part of the value last period $y_{(t-1)}$ is relevant in explaining the current one. 
$\theta_1$: Expresses average what part of the error last period $\in_{(t-1)}$ is relevant in explaining the current one. 
::: tip
The error term from the last period is used to help us correct our predictions.

@tab ARIMA
#### Background information
> In our previous tutorial, we became familiar with the ARMA model. But did you know that we can expand the ARMA model to <span style="color:orange">handle non-stationary data?</span>
> Well, that’s exactly what we’re going to cover in this post - the intuition behind the ARIMA model, the notation that goes with it, and how it differs from the ARMA model.

An ARIMA model has three orders – p, d, and q (ARIMA(p,d,q)). 
1. The “p” and “q” represent the autoregressive (AR) and moving average (MA) lags just like with the ARMA models. 
2. The “d” order is the <span style="color:orange">integration order</span>. It represents <span style="color:orange">the number of times</span> we need to <span style="color:orange">integrate the time series to ensure stationarity</span>, but more on that in just a bit.

#### What does a simple ARIMA (1,1,1) look like?
With all orders equal to 1. Suppose P is the price variable we’re trying to model. Then, the simple ARIMA equation for P would look as follows:
$\varDelta P_t = c + \phi_1 \varDelta P_{t-1} + \theta_1\in_{t-1} + \in_t$

$P_t$ and $P_{t-1}$: represent the values in the current period and 1 period ago respectively.
$ϵ_t$ and $ϵ_{t-1}$: are the error terms for the same two periods. 
$c$: is just a baseline constant factor. 
$ϕ_1$ and $θ_1$: express what parts of the value ($P_{t-1}$) and error ($ϵ_{t-1}$) last period are relevant in estimating the current one.
$ΔP_{t-1}$: the difference between prices in period “t” and prices in the preceding period ($ΔP_t = P_{t-1}-P_t$). 
$ΔP$: is an entire time-series, which represents the disparity between prices of consecutive periods.

@tab ARCH
Autoregressive conditional heteroskedasticity (ARCH) is a statistical model used to analyze <span style="color:orange;font-weight:bold;">volatility</span> in time series in order to forecast future volatility. In the financial world, ARCH modeling is used to <span style="color:orange;font-weight:bold;">estimate risk</span> by providing a model of volatility that more closely resembles real markets. <span style="color:red;font-weight:bold;">ARCH modeling shows that periods of high volatility are followed by more high volatility and periods of low volatility are followed by more low volatility</span>.

@tab GARCH
Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) is a statistical model used in analyzing time-series data where <span style="color:orange">the variance error is believed to be serially autocorrelated</span>. GARCH models assume that <span style="color:red">the variance of the error term</span> follows an <span style="color:red">autoregressive moving average process</span>.

> 1. GARCH is a statistical modeling technique used to help <span style="color:orange">predict the volatility of returns on financial assets</span>.
> 2. GARCH is appropriate for time series data where the variance of <span style="color:orange">the error term is serially autocorrelated</span> following an autoregressive moving average process. 
> 3. GARCH is useful to <span style="color:orange">assess risk and expected returns</span> for assets that exhibit clustered periods of volatility in returns.
:::

::: info References
01. [What Is an ARMA Model?](https://365datascience.com/tutorials/time-series-analysis-tutorials/arma-model/)
02. [What Is an Autoregressive Model?](https://365datascience.com/tutorials/time-series-analysis-tutorials/autoregressive-model/)
03. [What Is a Moving Average Model?](https://365datascience.com/tutorials/time-series-analysis-tutorials/moving-average-model/)
04. [Autoregressive Integrated Moving Average (ARIMA) Prediction Model](https://www.investopedia.com/terms/a/autoregressive-integrated-moving-average-arima.asp)
05. [What Is an ARIMA Model?](https://365datascience.com/tutorials/python-tutorials/arima/)
06. [Autoregressive Conditional Heteroskedasticity (ARCH) Explained](https://www.investopedia.com/terms/a/autoregressive-conditional-heteroskedasticity.asp)
07. [GARCH Model: Definition and Uses in Statistics](https://www.investopedia.com/terms/g/garch.asp#:~:text=What%20Is%20Generalized%20AutoRegressive%20Conditional,believed%20to%20be%20serially%20autocorrelated.)
08. [金融时间序列入门【完结篇】--- ARCH、GARCH](https://zhuanlan.zhihu.com/p/21962996)
09. [GARCH模型](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/fts-garch.html)
10. [Building a Univariate GARCH Model In Excel](https://towardsdatascience.com/building-a-univariate-garch-model-in-excel-dfb4c671eff7)
11. [ARCH model - volatility persistence in time series (Excel)](https://www.youtube.com/watch?v=-G5g3ChktEs)
:::


### What's gamma distribution
Gamma distribution is the maximum entropy probability distribution, which is defined by two parameters, which are shape parameter ***k*** and a scale parameter ***$\theta$***. Normally, using $\alpha$ = ***k*** to instead of ***k***, $\beta=\frac{1}{\theta}$ install of $\theta$ that is called rate parameter.

$\LARGE{f(x) = \frac{1}{\beta ^{\alpha}\varGamma(\alpha)}\int_{0}^{\infin}x^{r+\alpha-1}e^{-\frac{x}{\beta}}dx}$

$\varGamma(\alpha) = $

![Probability density function](https://upload.wikimedia.org/wikipedia/commons/e/e6/Gamma_distribution_pdf.svg =x300) 
![Cumulative distribution function](https://upload.wikimedia.org/wikipedia/commons/8/8d/Gamma_distribution_cdf.svg =x300)
 

#### References
[Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution)
<YouTube id="Sgo8iaCu7D0"/>
[gamma分布怎么做（gamma分布函数解析）](https://www.gsseo.net/yunying/18180.html)


### What's the likelihood
[](https://www.britannica.com/topic/expected-value)



### What's is Error Metrics

When considering the performance of any forecasting model, the prediction values it produces must be evaluated. This is done by calculating suitable error metrics. <span style="color:orange">An error metric is a way to quantify the performance</span> of a model and <span style="color:orange">provides a way for the forecaster to quantitatively compare different models</span>. They give us a way to more objectively gauge how well the model executes its tasks.

[Error Metrics: How to Evaluate Your Forecasts](https://www.jedox.com/en/blog/error-metrics-how-to-evaluate-forecasts/#:~:text=An%20error%20metric%20is%20a,the%20model%20executes%20its%20tasks.)